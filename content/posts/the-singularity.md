---
title: "The Singularity"
date: 2021-07-27T09:22:48-07:00
draft: true
---

What is a singularity?
In a black hole, the singularity is the point in the center of the black hole which, once you pass the event horizon, the gravity is so strong that you cant escape reaching the center, the singularity, and trying to talk to your daughter in the past with Morse code and sand.
There really is no way around it, so you should probably practice what you are gonna say before you cause a bunch of weird trauma and she doesn't realize what you were trying to send scientific data in the most convoluted way physically possible.

Would a technological singularity be, then?
A technological singularity actually has nothing to do with that physical definition or any physical definition of a black hole singularity, but it sure does sound cool.
The event horizon of a technological singularity is the point we may one day cross when an AI makes a smarter AI in an environment that is uncontrolled enough that we can't stop it from repeating this process indefinitely.
The point is, when we pass this event horizon, we have no idea what happens next.
And, whatever it is, we cannot stop it.
Now, some losers in the government or pop-science will tell you we should do everything we can to avoid this; the uncertainty being reason enough.
But can we?
If AI gets advanced enough, and there are enough different groups of people working on it, the odds of someone, *eventually*, fucking up and crossing the event horizon without us knowing is basically 100%.
So, for all intents and purposes, and barring some cataclysmic event or some unforseen barrier preventing us from making advanced AI, we have already crossed the event horizon.
Or, I guess the better metaphor would be that we have already been pulled in by its gravity, and our orbit intersects with the event horizon?
I don't know, who cares.

So whats the timeline then?
Well, people like Elon Musk will tell you it could happen at any second.
He has repeatedly made the claim that the AI apocolypse is coming, and that we need to do something about it.
Which is strange, because he *also* says, very often, that he is working on advanced AI to drive his cars.
So, if he was so worried about it, why doesn't he just stop working on his self driving cars and save us from the doom he himself said would come from doing exactly what he is currently doing, *hmmmmmmm*?
Well, the answer is the usual answer: Elon Musk is a big fat liar.
In fact, he's outdone himself and actually lied twice here. 
The premise, AND what he claims to be doing are both lies.
You thought he was bad for doing exactly what he shouldn't be doing, but in reality he wasn't doing it and it wasn't even a problem to begin with.
He really got you this time, you should have seen the look on your face.

Let' start with the "AI" he is working on.